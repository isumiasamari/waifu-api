# -*- coding: utf-8 -*-
import os
import uuid
import json
import asyncio
import time
from datetime import datetime
from pathlib import Path
from typing import Optional, List
import httpx
from fastapi import FastAPI, HTTPException, BackgroundTasks, Depends
from fastapi.security import HTTPBearer, HTTPAuthorizationCredentials
from fastapi.responses import FileResponse, JSONResponse
from pydantic import BaseModel
from dotenv import load_dotenv
import edge_tts

# ---------------------- å¯åŠ¨æ—¥å¿— ----------------------
print("=" * 50)
print("ğŸš€ å¯åŠ¨ Waifu Backend æœåŠ¡å™¨")
print("=" * 50)

load_dotenv()

APP_API_TOKEN = os.getenv("APP_API_TOKEN", "please-change-me")
API_KEY = os.getenv("API_KEY")
TTS_PROXY_URL = os.getenv("TTS_PROXY_URL", "").strip() or None

print(f"ğŸ” APP_API_TOKEN: {'å·²è®¾ç½®' if APP_API_TOKEN != 'please-change-me' else 'æœªè®¾ç½®'}")
print(f"ğŸ” API_KEY: {'å·²è®¾ç½®' if API_KEY else 'æœªè®¾ç½®'}")

# ---------------------- åˆå§‹åŒ– DeepSeek ----------------------
llm_client = None
if API_KEY:
    try:
        from openai import OpenAI
        llm_client = OpenAI(api_key=API_KEY, base_url="https://api.deepseek.com")
        print("âœ… DeepSeek å®¢æˆ·ç«¯åˆå§‹åŒ–æˆåŠŸ")
    except Exception as e:
        print("âŒ DeepSeek å®¢æˆ·ç«¯åˆå§‹åŒ–å¤±è´¥:", e)

# ---------------------- åŸºç¡€è·¯å¾„ ----------------------
DATA_DIR = Path(os.getenv("DATA_DIR", "server_data"))
AUDIO_DIR = DATA_DIR / "audio"
STATE_FILE = DATA_DIR / "state.json"
MAX_MEMORY = 30
AUDIO_TTL_SECONDS = 60 * 60

DATA_DIR.mkdir(parents=True, exist_ok=True)
AUDIO_DIR.mkdir(parents=True, exist_ok=True)

tts_lock = asyncio.Lock()

# ---------------------- FastAPI ----------------------
app = FastAPI(title="Waifu Backend (Edge-TTS + DeepSeek)")
security = HTTPBearer(auto_error=False)

# åœ¨ FastAPI ä¸­ä¿å­˜æ•…äº‹ä»»åŠ¡ï¼Œä¸è¦ç”¨ global
app.state.story_task = None

# ---------------------- æ•°æ®æ¨¡å‹ ----------------------
class ChatRequest(BaseModel):
    user_id: Optional[str] = "default_user"
    message: str

class ChatResponse(BaseModel):
    reply: str
    tts_url: Optional[str] = None

# ---------------------- å…¨å±€çŠ¶æ€ ----------------------
state = {
    "character": {"name": "éº»æ¯¬", "age": 18, "seikaku": "æ¸©æŸ”"},
    "memory": [],
    "story_mode": {
        "enabled": False,
        "last_reply": None,
        "last_time": None,
    }
}

if STATE_FILE.exists():
    try:
        state = json.loads(STATE_FILE.read_text(encoding="utf-8"))
    except:
        print("âš ï¸ state.json æŸåï¼Œé‡æ–°åˆå§‹åŒ–")

def save_state():
    STATE_FILE.write_text(json.dumps(state, ensure_ascii=False, indent=2), encoding="utf-8")

# ---------------------- é‰´æƒ ----------------------
async def check_auth(credentials: HTTPAuthorizationCredentials = Depends(security)):
    if not credentials:
        raise HTTPException(401, "Missing auth token")
    if credentials.credentials != APP_API_TOKEN:
        raise HTTPException(401, "Invalid token")
    return True

# ---------------------- è°ƒç”¨ DeepSeek ----------------------
async def call_llm_api(user_message: str, recent_memory: List[str]) -> str:
    if not llm_client:
        return "æŠ±æ­‰ï¼ŒAI æš‚ä¸å¯ç”¨ã€‚"

    system_prompt = """
è®¾å®šï¼šä½ æ˜¯éº»æ¯¬ã€‚
å›å¤éœ€è¦è¶…è¿‡ 100 å­—ï¼Œè‡ªç„¶ã€æ¸©æŸ”ã€è¿è´¯ã€‚
"""

    try:
        resp = llm_client.chat.completions.create(
            model="deepseek-chat",
            max_tokens=500,
            messages=[
                {"role": "system", "content": system_prompt + "\næœ€è¿‘å¯¹è¯ï¼š\n" + "\n".join(recent_memory)},
                {"role": "user", "content": user_message},
            ]
        )
        return resp.choices[0].message.content

    except Exception as e:
        print("âŒ LLM è°ƒç”¨å¤±è´¥:", e)
        return "æŠ±æ­‰ï¼Œæˆ‘æœ‰ç‚¹å¤´æ™•â€¦â€¦å…ˆä¼‘æ¯ä¸€ä¸‹~"
# ---------------------- Edge-TTS ç”Ÿæˆ ----------------------
async def synthesize_tts(
        text: str,
        voice: str = "zh-CN-XiaoyiNeural",
        rate: str = "-5%",
        pitch: str = "+30Hz",
) -> Path:
    async with tts_lock:
        timestamp = int(time.time() * 1000)
        filename = f"reply_{timestamp}.mp3"
        dest = AUDIO_DIR / filename

        # -------- ä¼˜å…ˆè°ƒç”¨ TTS ä»£ç†ï¼ˆä½ çš„æœ¬åœ°ç”µè„‘ï¼‰--------
        if TTS_PROXY_URL:
            try:
                async with httpx.AsyncClient(timeout=60.0) as client:
                    resp = await client.post(
                        TTS_PROXY_URL,
                        json={
                            "text": text,
                            "voice": voice,
                            "rate": rate,
                            "pitch": pitch
                        },
                    )

                if resp.status_code != 200:
                    raise RuntimeError(f"TTS ä»£ç†å¤±è´¥: {resp.text[:200]}")

                dest.write_bytes(resp.content)

            except Exception as e:
                raise HTTPException(503, f"TTS ä»£ç†å¤±è´¥: {e}")

        else:
            # -------- Fallbackï¼šäº‘ç«¯è‡ªå·±ç”Ÿæˆï¼ˆä¸æ¨èï¼‰--------
            communicate = edge_tts.Communicate(
                text=text,
                voice=voice,
                rate=rate,
                pitch=pitch,
            )
            await communicate.save(str(dest))

        # meta ä¿¡æ¯
        (dest.with_suffix(".mp3.meta")).write_text(
            json.dumps({"created": datetime.utcnow().isoformat()})
        )
        return dest


# ---------------------- è‡ªåŠ¨è®²æ•…äº‹åå°ä»»åŠ¡ ----------------------
async def story_loop():
    """
    è‡ªåŠ¨è®²æ•…äº‹å¾ªç¯ï¼š
    - æ¯ 1 åˆ†é’Ÿå‘ä¸€æ¡
    - ä½¿ç”¨ story_memory åšä¸Šä¸‹æ–‡
    """
    print("ğŸ“šã€æ•…äº‹æ¨¡å¼ã€‘åå°ä»»åŠ¡å¯åŠ¨")

    while state["story_mode"]["enabled"]:
        try:
            memory = state["story_mode"]["story_memory"][-10:]
            prompt = "ç»­å†™åˆšæ‰çš„æ•…äº‹ï¼Œç»§ç»­è®²ä¸‹ä¸€æ®µï¼Œä¿æŒè¿è´¯ï¼Œè‡³å°‘ 120 å­—ã€‚"

            reply = await call_llm_api(prompt, memory)

            # ä¿å­˜è¿›æ•…äº‹ memory
            state["story_mode"]["story_memory"].append({"role": "assistant", "text": reply})
            save_state()

            # ç”Ÿæˆ TTS
            await synthesize_tts(
                reply,
                voice="zh-CN-XiaoyiNeural",
                rate="-5%",
                pitch="+30Hz"
            )

            print("ğŸ“šã€æ•…äº‹æ¨¡å¼ã€‘å·²ç”Ÿæˆæ–°çš„æ®µè½")

        except Exception as e:
            print("âŒ æ•…äº‹ç”Ÿæˆå¤±è´¥ï¼š", e)

        await asyncio.sleep(60)   # æ¯ 1 åˆ†é’Ÿä¸€æ®µ

    print("ğŸ“•ã€æ•…äº‹æ¨¡å¼ã€‘åå°ä»»åŠ¡ç»“æŸ")
# ---------------------- API: æ™®é€šèŠå¤© ----------------------
@app.post("/chat", response_model=ChatResponse)
async def chat_endpoint(
        req: ChatRequest,
        background_tasks: BackgroundTasks,
        auth: bool = Depends(check_auth)
):
    msg = req.message.strip()

    # ===== ç‰¹æ®Šå‘½ä»¤ =====
    if msg == "å¼€å§‹":
        state["story_mode"]["enabled"] = True
        save_state()

        if app.state.story_task is None or app.state.story_task.done():
            app.state.story_task = asyncio.create_task(story_loop())

        return ChatResponse(reply="å¥½çš„ä¸»äººï¼Œæˆ‘ä¼šå¼€å§‹ä¸ºä½ è¿è´¯åœ°è®²æ•…äº‹~", tts_url=None)

    if msg == "åœ":
        state["story_mode"]["enabled"] = False
        save_state()
        return ChatResponse(reply="å·²ç»åœä¸‹æ•…äº‹äº†~", tts_url=None)

    if msg == "ç»§ç»­":
        state["story_mode"]["enabled"] = True
        save_state()

        if app.state.story_task is None or app.state.story_task.done():
            app.state.story_task = asyncio.create_task(story_loop())

        return ChatResponse(reply="å—¯~æˆ‘æ¥ç€è®²åˆšæ‰çš„æ•…äº‹~", tts_url=None)

    # ===== æ™®é€šèŠå¤© =====
    state["memory"].append({"role": "user", "text": msg})
    state["memory"] = state["memory"][-MAX_MEMORY:]
    save_state()

    recent_memory = [f"{m['role']}: {m['text']}" for m in state["memory"][-10:]]
    reply_text = await call_llm_api(msg, recent_memory)

    state["memory"].append({"role": "assistant", "text": reply_text})
    save_state()

    # ---- åå°ç”Ÿæˆ TTS ----
    async def gen():
        try:
            await synthesize_tts(
                reply_text,
                voice="zh-CN-XiaoyiNeural",
                rate="-5%",
                pitch="+30Hz"
            )
        except Exception as e:
            print("TTS failed:", e)

    background_tasks.add_task(gen)

    return ChatResponse(reply=reply_text, tts_url=None)


# ---------------------- å…¶ä»– API ----------------------
@app.post("/tts")
async def tts_endpoint(payload: dict, auth: bool = Depends(check_auth)):
    text = payload.get("text")
    audio_path = await synthesize_tts(text)
    return FileResponse(audio_path, media_type="audio/mpeg", filename=audio_path.name)


@app.get("/state")
def get_state(auth: bool = Depends(check_auth)):
    return JSONResponse(state)


# ---------------------- å¯åŠ¨äº‹ä»¶ ----------------------
from contextlib import asynccontextmanager

@asynccontextmanager
async def lifespan(app: FastAPI):
    print("ğŸš€ Backend Starting...")
    if state["story_mode"]["enabled"]:
        print("ğŸ“š æ£€æµ‹åˆ°æ•…äº‹æ¨¡å¼å¼€å¯ï¼Œè‡ªåŠ¨æ¢å¤ä»»åŠ¡")
        app.state.story_task = asyncio.create_task(story_loop())
    yield
    print("ğŸ›‘ Backend Stopping...")

# é‡æ–°åˆ›å»º appï¼ˆå¸¦ lifespanï¼‰
app = FastAPI(title="Waifu Backend", lifespan=lifespan)

# é‡æ–°æ³¨å†Œè·¯ç”±ï¼ˆå¿…é¡»ä¿æŒï¼‰
app.post("/chat", response_model=ChatResponse)(chat_endpoint)
app.post("/tts")(tts_endpoint)
app.get("/state")(get_state)
